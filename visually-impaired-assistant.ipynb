{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea549409-4a48-4f17-a4a5-31cde6b4b4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòä Detected Emotion: happy\n",
      "\n",
      "0: 384x640 1 person, 1 bed, 2 laptops, 230.1ms\n",
      "Speed: 2.4ms preprocess, 230.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "üîç Detected Objects: laptop, person, bed, laptop\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8l.pt\")  \n",
    "\n",
    "# IP webcam URL\n",
    "cam_url = \"http://10.193.209.160:8080/video\"\n",
    "\n",
    "# Directory to save images\n",
    "save_dir = \"captured_images\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "def preprocess_for_ocr(image):\n",
    "    \"\"\"Prepares image for OCR with adaptive thresholding and noise removal.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    return binary\n",
    "\n",
    "def detect_objects(frame):\n",
    "    \"\"\"Detects objects and draws bounding boxes.\"\"\"\n",
    "    results = model(frame, conf=0.4)  \n",
    "    detected_objects = []\n",
    "    text_regions = []\n",
    "    \n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  \n",
    "            label = result.names[int(box.cls[0])]  \n",
    "            conf = float(box.conf[0])  \n",
    "            \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{label} {conf:.2f}\", (x1, y1 - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            detected_objects.append(label)\n",
    "            if label in [\"book\", \"screen\", \"paper\", \"signboard\"]:\n",
    "                text_regions.append(frame[y1:y2, x1:x2])\n",
    "    \n",
    "    return frame, text_regions, detected_objects\n",
    "\n",
    "def run_ocr(text_regions):\n",
    "    \"\"\"Runs OCR on detected text regions.\"\"\"\n",
    "    ocr_text = \"\"\n",
    "    for idx, region in enumerate(text_regions):\n",
    "        processed_region = preprocess_for_ocr(region)\n",
    "        text = pytesseract.image_to_string(processed_region, config=\"--psm 6 --oem 3\").strip()\n",
    "        if text:\n",
    "            ocr_text += f\"\\nüî§ Text from region {idx + 1}:\\n{text}\\n\"\n",
    "    \n",
    "    return ocr_text.strip()\n",
    "\n",
    "def detect_emotion(frame):\n",
    "    \"\"\"Detects emotion from the given frame.\"\"\"\n",
    "    try:\n",
    "        result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "        if isinstance(result, list) and result:\n",
    "            return result[0]['dominant_emotion']\n",
    "    except Exception as e:\n",
    "        print(\"Error detecting emotion:\", e)\n",
    "    return \"None\"\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(cam_url)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to access IP webcam\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                break\n",
    "            \n",
    "            cv2.imshow(\"Live Feed\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord('o'):\n",
    "                processed_frame, text_regions, detected_objects = detect_objects(frame)\n",
    "                if detected_objects:\n",
    "                    print(\"üîç Detected Objects:\", \", \".join(detected_objects))\n",
    "                else:\n",
    "                    print(\"No objects detected.\")\n",
    "                \n",
    "            elif key == ord('t'):\n",
    "                processed_frame, text_regions, _ = detect_objects(frame)\n",
    "                ocr_text = run_ocr(text_regions)\n",
    "                if ocr_text:\n",
    "                    print(ocr_text)\n",
    "                else:\n",
    "                    print(\"No text detected.\")\n",
    "                \n",
    "            elif key == ord('e'):\n",
    "                emotion = detect_emotion(frame)\n",
    "                print(f\"üòä Detected Emotion: {emotion}\")\n",
    "                \n",
    "            elif key == ord('q'):\n",
    "                break\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nüî¥ Interrupted by user.\")\n",
    "    \n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e5f038-c14a-4603-885e-6b353adbc56c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
